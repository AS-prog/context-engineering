# ğŸ“š Ejemplos de Workflows - IngenierÃ­a de Contexto

**VersiÃ³n**: 1.0  
**Ãšltima actualizaciÃ³n**: Jan 23, 2025  
**PropÃ³sito**: Ejemplos reales y prÃ¡cticos de cÃ³mo usar el sistema de agentes para resolver problemas comunes.

---

## ğŸ“‹ Tabla de Contenidos

1. [Ejemplo 1: Email Validator](#ejemplo-1-email-validator)
2. [Ejemplo 2: Data Pipeline CSVâ†’PostgreSQL](#ejemplo-2-data-pipeline-csvpostgresql)
3. [Ejemplo 3: REST API with FastAPI](#ejemplo-3-rest-api-with-fastapi)
4. [Ejemplo 4: Data Transformation](#ejemplo-4-data-transformation)
5. [Ejemplo 5: Database Schema Migration](#ejemplo-5-database-schema-migration)
6. [Ejemplo 6: CLI Tool con Click](#ejemplo-6-cli-tool-con-click)

---

## ğŸ”‘ Ejemplo 1: Email Validator

**Caso de Uso**: Crear un validador de emails reutilizable con Pydantic y tests.

**Complejidad**: â­â­ (BÃ¡sico)  
**Tiempo**: ~1 minuto  
**Agentes Usados**: git-manager, tdd-architect, python-coder

### Estructura Final
```
email-validator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ validators.py          # Email validator class
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_validators.py      # Tests con TDD
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

### Prompt

```
@data-engineer

"Necesito crear un mÃ³dulo validador de emails que:

REQUERIMIENTOS FUNCIONALES:
- Validar formato de email (debe tener @)
- Validar dominio vÃ¡lido (ej: ejemplo.com)
- Validar longitud mÃ¡xima 254 caracteres
- Validar longitud mÃ­nima 5 caracteres
- Case-insensitive para emails
- Lanzar ValueError si no es vÃ¡lido

REQUERIMIENTOS TÃ‰CNICOS:
- Usar Pydantic BaseModel con EmailStr
- Type hints en todas las funciones
- Docstrings en Google Style (espaÃ±ol)
- PEP 8 compliance
- Tests con pytest cubriendo:
  * Happy path: email vÃ¡lido
  * Edge cases: mÃ­nimo/mÃ¡ximo longitud
  * Error cases: formato invÃ¡lido, sin @

ESTRUCTURA:
- src/validators.py: Clase EmailValidator
- tests/test_validators.py: Suite de tests TDD

Incluir docstrings ESCENARIO/COMPORTAMIENTO/PROPÃ“SITO en cada test."
```

### Salida Esperada

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¤– AGENTE: data-engineer | INVOCACIÃ“N INICIADA
ğŸ“‹ Tarea: Crear validador de emails con Pydantic
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[AnÃ¡lisis...]
Plan de ejecuciÃ³n:
1. Crear rama feature/email-validator
2. DiseÃ±ar tests (RED phase)
3. Implementar validador (GREEN phase)
4. Hacer commit

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¤– AGENTE: git-manager | INVOCACIÃ“N INICIADA
ğŸ“‹ Tarea: Crear rama feature/email-validator
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[Crea rama...]
âœ… AGENTE: git-manager | TAREA COMPLETADA
ğŸ“¦ Artefactos:
   - Rama feature/email-validator creada

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¤– AGENTE: tdd-architect | INVOCACIÃ“N INICIADA
ğŸ“‹ Tarea: DiseÃ±ar tests para validador de emails
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[Crea tests...]
âœ… AGENTE: tdd-architect | TAREA COMPLETADA
ğŸ“¦ Artefactos:
   - tests/test_validators.py

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¤– AGENTE: python-coder | INVOCACIÃ“N INICIADA
ğŸ“‹ Tarea: Implementar validador de emails
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[Implementa...]
âœ… AGENTE: python-coder | TAREA COMPLETADA
ğŸ“¦ Artefactos:
   - src/validators.py

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… AGENTE: data-engineer | WORKFLOW COMPLETADO
ğŸ“¦ Artefactos Finales:
   - src/validators.py (EmailValidator class)
   - tests/test_validators.py (5 tests)
   - Rama feature/email-validator
   - Commit feat: crear validador de emails con pydantic
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### VerificaciÃ³n

```bash
# Ver rama
git branch -a

# Correr tests
pytest tests/ -v
# Output: 5 passed in 0.50s

# Ver estructura
tree src tests

# Ver commits
git log --oneline -3
```

---

## ğŸ“Š Ejemplo 2: Data Pipeline CSVâ†’PostgreSQL

**Caso de Uso**: Crear un pipeline que lee CSV y lo carga en PostgreSQL con validaciÃ³n.

**Complejidad**: â­â­â­â­ (Avanzado)  
**Tiempo**: ~3-5 minutos  
**Agentes Usados**: git-manager, sql-specialist, tdd-architect, python-coder

### Estructura Final
```
csv-to-postgres/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database.py            # PostgreSQL connection
â”‚   â”œâ”€â”€ models.py              # Pydantic models
â”‚   â”œâ”€â”€ pipeline.py            # ETL pipeline
â”‚   â””â”€â”€ config.py              # Configuration
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_pipeline.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample.csv             # Datos de ejemplo
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ schema.sql             # Schema SQL
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### Prompt

```
@data-engineer

"Necesito crear un ETL pipeline CSVâ†’PostgreSQL que:

REQUERIMIENTOS FUNCIONALES:
1. Leer CSV con estructura:
   - id (integer)
   - name (string)
   - email (string)
   - age (integer)
   - country (string)

2. Validar datos:
   - Email vÃ¡lido (regex o EmailStr)
   - Age entre 18-120
   - Name no vacÃ­o
   - Id Ãºnico

3. Transformar:
   - Normalizar emails (minÃºsculas)
   - Validar datos con Pydantic
   - Manejo de filas invÃ¡lidas (log + skip)

4. Cargar en PostgreSQL:
   - Crear tabla users
   - Insertar datos vÃ¡lidos
   - Transacciones
   - Rollback si hay error

REQUERIMIENTOS TÃ‰CNICOS:
- src/database.py: PostgreSQL connection pool
- src/models.py: Pydantic models para validaciÃ³n
- src/pipeline.py: Main ETL logic
- sql/schema.sql: Schema SQL
- Type hints everywhere
- Docstrings Google Style
- PEP 8 compliant
- Tests cubriendo:
  * CSV reading
  * ValidaciÃ³n Pydantic
  * Database insertion
  * Error handling

STACK:
- pandas para CSV
- sqlalchemy para DB
- pydantic para validaciÃ³n
- psycopg2 para PostgreSQL
- pytest para tests"
```

### Prompt Alternativo Simplificado

Si quieres dividirlo en pasos:

```
@data-engineer "Paso 1: Crear modelos Pydantic para usuario"
@data-engineer "Paso 2: Crear database.py con SQLAlchemy"
@data-engineer "Paso 3: Crear pipeline.py con lÃ³gica ETL"
@data-engineer "Paso 4: Crear tests para todo"
```

### VerificaciÃ³n

```bash
# Ver estructura
tree src sql tests

# Correr tests
pytest tests/ -v

# Probar pipeline con datos reales
python -c "
from src.pipeline import Pipeline
p = Pipeline('postgresql://user:pass@localhost/dbname')
results = p.run('data/sample.csv')
print(f'Loaded {results.success} rows')
"

# Verificar BD
psql -U user -d dbname -c "SELECT * FROM users;"
```

---

## ğŸŒ Ejemplo 3: REST API with FastAPI

**Caso de Uso**: Crear una REST API con FastAPI para gestionar usuarios.

**Complejidad**: â­â­â­â­â­ (Muy Avanzado)  
**Tiempo**: ~5-8 minutos  
**Agentes Usados**: Todos (git, sql, tdd, python)

### Estructura Final
```
user-api/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI app
â”‚   â”œâ”€â”€ models.py               # Pydantic models
â”‚   â”œâ”€â”€ database.py             # DB config
â”‚   â”œâ”€â”€ schemas.py              # API schemas
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ users.py            # User endpoints
â”‚   â””â”€â”€ crud/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ users.py            # CRUD operations
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_api_users.py
â”‚   â””â”€â”€ test_crud_users.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

### Prompt

```
@data-engineer

"Crear API REST con FastAPI para gestionar usuarios:

ENDPOINTS:
POST   /api/users           - Crear usuario
GET    /api/users           - Listar usuarios (con paginaciÃ³n)
GET    /api/users/{id}      - Obtener usuario
PUT    /api/users/{id}      - Actualizar usuario
DELETE /api/users/{id}      - Eliminar usuario

MODELOS:
User:
- id: integer
- email: string (Ãºnico, valid email)
- name: string (1-100 chars)
- age: integer (18-120)
- is_active: boolean
- created_at: datetime
- updated_at: datetime

VALIDACIÃ“N:
- Email vÃ¡lido con EmailStr
- Nombre no vacÃ­o y min 3 chars
- Age dentro de rango
- Unique constraint en email
- Soft delete (is_active)

DOCUMENTACIÃ“N:
- OpenAPI/Swagger automÃ¡tico
- Type hints everywhere
- Docstrings detallados
- Response models con ejemplos

TESTS:
- Test cada endpoint
- Test validaciones
- Test edge cases
- Test errores (404, 422, 409)
- Min 85% coverage

STACK:
- FastAPI
- SQLAlchemy ORM
- Pydantic
- PostgreSQL
- pytest + TestClient
- python-dotenv para config"
```

### VerificaciÃ³n

```bash
# Instalar dependencias
pip install -r requirements.txt

# Correr servidor
uvicorn src.main:app --reload

# En otra terminal: correr tests
pytest tests/ -v --cov=src

# Acceder a docs
open http://localhost:8000/docs
```

---

## ğŸ”„ Ejemplo 4: Data Transformation

**Caso de Uso**: Transformar datos de mÃºltiples fuentes a formato estÃ¡ndar.

**Complejidad**: â­â­â­ (Intermedio)  
**Tiempo**: ~3 minutos  
**Agentes Usados**: git-manager, python-coder, tdd-architect

### Prompt

```
@data-engineer

"Crear module de transformaciÃ³n de datos que:

ENTRADA (3 formatos diferentes):
1. CSV plano: id,name,email,phone
2. JSON anidado: {users: [{id, name, contact: {email, phone}}]}
3. Excel sheets: Users sheet con columnas

SALIDA (Formato estÃ¡ndar):
User:
- user_id (integer)
- full_name (string, title case)
- email (string, lowercase)
- phone (string, formato internacional)
- source (string: csv|json|excel)
- processed_at (datetime)

TRANSFORMACIONES:
- Renombrar columnas (id â†’ user_id, name â†’ full_name)
- Normalizar formatos (emails lowercase, phones int'l format)
- Validar con Pydantic
- Agregar metadata (source, timestamp)
- Manejo de valores nulos
- Logging de errores

ESTRUCTURA:
- src/transformers.py: Clase base + implementations
- src/validators.py: Pydantic models
- tests/test_transformers.py: Tests para cada formato

REQUERIMIENTOS:
- Type hints completos
- Docstrings Google Style
- PEP 8
- 100% test coverage
- Manejar archivos corruptos gracefully"
```

---

## ğŸ—„ï¸ Ejemplo 5: Database Schema Migration

**Caso de Uso**: DiseÃ±ar y crear schema de base de datos desde cero.

**Complejidad**: â­â­â­â­ (Avanzado)  
**Tiempo**: ~4 minutos  
**Agentes Usados**: sql-specialist, python-coder, tdd-architect

### Prompt

```
@data-engineer

"DiseÃ±ar schema SQL para e-commerce que:

ENTIDADES:
1. users:
   - id, email (unique), password, name, created_at, is_active

2. products:
   - id, sku (unique), name, description, price, stock, category_id

3. categories:
   - id, name (unique), description

4. orders:
   - id, user_id, created_at, status (pending|processing|shipped|delivered)

5. order_items:
   - id, order_id, product_id, quantity, price

REQUERIMIENTOS:
- Foreign keys con cascade
- Ãndices en bÃºsquedas frecuentes
- Constraints de integridad
- Default values sensatos
- Timestamps (created_at, updated_at)
- Soft deletes donde sea apropiado

SALIDA:
1. sql/schema.sql: Schema con comentarios
2. src/database.py: SQLAlchemy models
3. src/migrations.py: Alembic migrations
4. tests/test_schema.py: Tests de integridad

VALIDACIONES A PROBAR:
- Foreign key constraints
- Unique constraints
- Check constraints (price > 0, stock >= 0)
- Indexes existen
- Relationships funcionan"
```

---

## ğŸ’» Ejemplo 6: CLI Tool con Click

**Caso de Uso**: Crear herramienta CLI para procesar datos.

**Complejidad**: â­â­â­ (Intermedio)  
**Tiempo**: ~2-3 minutos  
**Agentes Usados**: git-manager, python-coder, tdd-architect

### Estructura Final
```
data-cli/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py                 # Click commands
â”‚   â”œâ”€â”€ processors.py          # Business logic
â”‚   â””â”€â”€ utils.py               # Utilities
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_cli.py
â”‚   â””â”€â”€ test_processors.py
â”œâ”€â”€ setup.py                   # Entry point
â””â”€â”€ README.md
```

### Prompt

```
@data-engineer

"Crear CLI tool con Click para procesar archivos:

COMANDOS:
1. data validate <file>
   - Valida CSV contra schema
   - Output: âœ… Valid o âŒ Invalid + errores

2. data transform <input> <output>
   - Lee CSV, transforma, escribe CSV normalizado
   - Opciones: --format (json|csv|parquet)

3. data stats <file>
   - EstadÃ­sticas del archivo
   - Muestra: rows, columns, tipos, nulos

4. data merge <file1> <file2> <output>
   - Combina 2 archivos
   - OpciÃ³n: --on <column> para join

REQUISITOS:
- Usar Click framework
- Commands con help text detallado
- Progress bars para archivos grandes
- Manejo de errores user-friendly
- Colores en output (verde=success, rojo=error)
- Logging a archivo opcional (--verbose)

ESTRUCTURA:
- src/cli.py: Click command groups
- src/processors.py: LÃ³gica de procesamiento
- tests/test_cli.py: Tests con CliRunner
- setup.py: Entry point para instalaciÃ³n

INSTALACIÃ“N:
pip install -e .
data --help

TESTS:
- Cada comando testeable
- Test inputs invÃ¡lidos
- Mock de archivos
- Verificar output messages"
```

---

## ğŸ¯ Ejemplo 7: API de Recomendaciones (Avanzado)

**Caso de Uso**: Sistema de recomendaciones basado en historial del usuario.

**Complejidad**: â­â­â­â­â­ (Muy Avanzado)  
**Tiempo**: ~8-10 minutos  
**Agentes Usados**: Todos

### Prompt Resumido

```
@data-engineer

"Crear API de recomendaciones que:

1. Almacena interacciones del usuario (view, click, purchase)
2. Calcula similitud entre items (cosine similarity)
3. Genera recomendaciones personalizadas
4. Aprende con feedback (A/B testing)

ENDPOINTS:
- POST /interactions: Registrar interacciÃ³n
- GET /recommendations/{user_id}: Get recomendaciones
- POST /feedback: Registrar feedback (helped/not-helpful)

MACHINE LEARNING:
- TF-IDF para descripciÃ³n de items
- Cosine similarity entre vectores
- Collaborative filtering simple

TESTS:
- Test recomendaciones correctas
- Test feedback actualiza modelo
- Test cold-start problem (new user)

STACK:
- FastAPI
- Scikit-learn para ML
- PostgreSQL para datos
- Redis para caching"
```

---

## ğŸ“‹ Checklist para Cualquier Workflow

**Antes de Invocar**:
- [ ] EspecificaciÃ³n clara y detallada
- [ ] Dividir si es muy complejo
- [ ] Listar requisitos funcionales y tÃ©cnicos
- [ ] Mencionar stack/dependencies

**DespuÃ©s de Completar**:
- [ ] Revisar estructura generada
- [ ] Correr tests localmente
- [ ] Revisar commits creados
- [ ] Revisar code quality (flake8, black, mypy)
- [ ] Revisar documentaciÃ³n generada

---

## ğŸš€ Tips para Mejores Resultados

1. **Ser EspecÃ­fico**: En lugar de "crear API", mencionar exactamente quÃ© endpoints
2. **Dar Contexto**: "Para e-commerce de ropa" vs solo "crear API"
3. **Listar Requirements**: Funcionales y tÃ©cnicos separados
4. **Especificar Stack**: "Usar FastAPI, SQLAlchemy, pytest"
5. **Dar Ejemplos**: Estructura deseada, ejemplos de entrada/salida
6. **Dividir si Necesario**: Mejor 3 workflows simples que 1 complejo

---

## ğŸ“ MÃ¡s Ejemplos?

Para mÃ¡s ejemplos, consulta:
- **[CONTRIBUTING.md](../CONTRIBUTING.md)** - SecciÃ³n "Flujos de Trabajo"
- **[docs/PRUEBA_ORQUESTACION.md](./PRUEBA_ORQUESTACION.md)** - Email validator en detalle
- **[AGENTS.md](../AGENTS.md)** - GuÃ­a general

---

**Ãšltima actualizaciÃ³n**: Jan 23, 2025  
**VersiÃ³n**: 1.0
